{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analise de Emoções em Brinquedos de Parques de Diversões (IA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo é determinar as emoções que são sentidas durante o uso dos brinquedos no parque de diversão, gerando um relatório com as emoções ponderadas de acordo com o áudio capturado. Assim podendo comparar as emoções que são esperadas para determinados brinquedos e as que realmente são obtidas. As emoções analisadas são: \n",
    "\n",
    "1. Felicidade\n",
    "2. Medo\n",
    "3. Desgosto\n",
    "4. Tristeza\n",
    "5. Neutra\n",
    "6. Raiva \n",
    "\n",
    "E os brinquedos utilizados utilizados como exemplo no projeto, são:\n",
    "\n",
    "1. Montanha Russa\n",
    "2. Casa dos Monstros\n",
    "3. Carrinho Bate-Bate\n",
    "4. Roda Gigante\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as bibliotecas necessários para o projeto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "from sklearn.tree import DecisionTreeClassifier as tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from loop_listen.loop_listen import Loop_listen as Loop\n",
    "import sklearn.tree as SKTree\n",
    "import matplotlib.pyplot as plt\n",
    "from reportlab.pdfgen import canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declarando as variáveis globais. \n",
    "\n",
    "directories: Lista dos diretorios no qual estão localizados os audios para treinamento da IA (Inteligência Artificial) \n",
    "\n",
    "emotionStorage: Lista de arrays responsável pelo armazenamento obtidos durante a utilização dos brinquedos (gravação dos audios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = ['/0_happy', '/1_fear', '/2_disgust', '/3_sad', '/4_neutral', '/5_angry']\n",
    "emotionStorage = [[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função responsável pela criação e organização dos dataset (base de dados) que serão utilizados. \n",
    "\n",
    "O dataset será composto pelas seguintes features (atributos): \n",
    "\n",
    "genre - Podendo ser 0 para mulher e 1 para homem.\n",
    "\n",
    "mfcc - Técnica para extração de atributos com o objetivo de converter o espectro da voz para a escala MEL, uma escala que visa copiar as características básicas e únicas que o ouvido humano pode ouvir.\n",
    "\n",
    "stft - É uma sequência de transformadas de Fourier, a qual fornece informações de frequências localizadas no tempo.\n",
    "\n",
    "chromagram - Entende-se como um descrito que representa o material tonal de um sinal de áudio.\n",
    "\n",
    "mel - Escala que visa copiar as características básicas e únicas que o ouvido humano pode ouvir.\n",
    "\n",
    "contrast - Técnica utilizada para reduções de ruídos.\n",
    " \n",
    "tonnetz - É uma representação plana entre os tons musicais.\n",
    "\n",
    "emotion :  0: happy, 1: fear, 2: disgust, 3: sad, 4: neutral, 5: angry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organizeDataFrames():\n",
    "    aux = 0\n",
    "    for dir in directories:\n",
    "        print(dir)\n",
    "        maleFiles = os.listdir('data/MaleSounds' + dir)\n",
    "        df_male = pd.DataFrame(maleFiles)\n",
    "        df_male['genre'] = '1'\n",
    "        df_male['mfcc'] = '0'\n",
    "        df_male['stft'] = '0'\n",
    "        df_male['chromagram'] = '0'\n",
    "        df_male['mel'] = '0'\n",
    "        df_male['contrast'] = '0'\n",
    "        df_male['tonnetz'] = '0'\n",
    "        df_male['emotion'] = str(aux)\n",
    "        df_male = df_male.rename(columns={0: 'file'})\n",
    "\n",
    "        femaleFiles = os.listdir('data/FemaleSounds' + dir)\n",
    "        df_female = pd.DataFrame(femaleFiles)\n",
    "        df_female['genre'] = '0'\n",
    "        df_female['mfcc'] = '0'\n",
    "        df_female['stft'] = '0'\n",
    "        df_female['chromagram'] = '0'\n",
    "        df_female['mel'] = '0'\n",
    "        df_female['contrast'] = '0'\n",
    "        df_female['tonnetz'] = '0'\n",
    "        df_female['emotion'] = str(aux)\n",
    "        df_female = df_female.rename(columns={0: 'file'})\n",
    "\n",
    "        if aux == 0:\n",
    "            df1 = df_male\n",
    "            df2 = df_female\n",
    "            aux = aux + 1\n",
    "        elif aux > 0:\n",
    "            df1 = pd.concat([df1, df_male], ignore_index=True)\n",
    "            df2 = pd.concat([df2, df_female], ignore_index=True)\n",
    "            aux = aux + 1\n",
    "\n",
    "    df_voices = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "    return df_voices, df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-f2ddcefd46c6>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-f2ddcefd46c6>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Função responsável pelo processamento dos sinas dos audios da base de dados escolhida. Após isso, é armazenado no dataset.\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Função responsável pelo processamento dos sinas dos audios da base de dados escolhida. Após isso, é armazenado no dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFeatures(df_voices, path_1, path_2):\n",
    "    for x in df_voices.values:\n",
    "        if x[1] == '1':\n",
    "            if x[8] == '0':\n",
    "                fileName = './data/MaleSounds/0_happy' + '/' + str(x[0])\n",
    "            if x[8] == '1':\n",
    "                fileName = './data/MaleSounds/1_fear' + '/' + str(x[0])\n",
    "            if x[8] == '2':\n",
    "                fileName = './data/MaleSounds/2_disgust' + '/' + str(x[0])\n",
    "            if x[8] == '3':\n",
    "                fileName = './data/MaleSounds/3_sad' + '/' + str(x[0])\n",
    "            if x[8] == '4':\n",
    "                fileName = './data/MaleSounds/4_neutral' + '/' + str(x[0])\n",
    "            if x[8] == '5':\n",
    "                fileName = './data/MaleSounds/5_angry' + '/' + str(x[0])\n",
    "        if x[1] == '0':\n",
    "            if x[8] == '0':\n",
    "                fileName = './data/FemaleSounds/0_happy' + '/' + str(x[0])\n",
    "            if x[8] == '1':\n",
    "                fileName = './data/FemaleSounds/1_fear' + '/' + str(x[0])\n",
    "            if x[8] == '2':\n",
    "                fileName = './data/FemaleSounds/2_disgust' + '/' + str(x[0])\n",
    "            if x[8] == '3':\n",
    "                fileName = './data/FemaleSounds/3_sad' + '/' + str(x[0])\n",
    "            if x[8] == '4':\n",
    "                fileName = './data/FemaleSounds/4_neutral' + '/' + str(x[0])\n",
    "            if x[8] == '5':\n",
    "                fileName = './data/FemaleSounds/5_angry' + '/' + str(x[0])\n",
    "                \n",
    "        sound, sr = librosa.load(fileName, res_type='kaiser_fast')\n",
    "        # mel-frequency cepstral coefficient\n",
    "        mfcc = np.mean(librosa.feature.mfcc(y=sound, sr=sr, n_mfcc=40).T, axis=0)\n",
    "        x[2] = np.mean(mfcc)\n",
    "        # Fourier transformation\n",
    "        stft = np.abs(librosa.stft(sound))\n",
    "        x[3] = np.mean(stft)\n",
    "        # Chromagram\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sr).T, axis=0)\n",
    "        x[4] = np.mean(chroma)\n",
    "        # mel-scaled spectrogram\n",
    "        mel = np.mean(librosa.feature.melspectrogram(sound, sr=sr).T, axis=0)\n",
    "        x[5] = np.mean(mel)\n",
    "        # spectral contrast\n",
    "        contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sr).T, axis=0)\n",
    "        x[6] = np.mean(contrast)\n",
    "        # tonnetz\n",
    "        tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(sound),\n",
    "                                                  sr=sr).T, axis=0)\n",
    "        x[7] = np.mean(tonnetz)\n",
    "\n",
    "    df_target = df_voices.drop(['file', 'mfcc', 'stft', \n",
    "                                'chromagram', 'mel', 'contrast', 'tonnetz'], axis=1)\n",
    "    \n",
    "    df_voices = df_voices.drop(['file'], axis=1)\n",
    "\n",
    "    df_voices.to_csv(path_2, index=False)\n",
    "    df_target.to_csv(path_1, index=False)\n",
    "\n",
    "    return df_voices, df_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SplitAudio é utilizada para a divisão de um intevalo de audio 10 segundos em pedaços menores, de 1 segundo cada. \n",
    "\n",
    "#reference: https://stackoverflow.com/questions/37999150/how-to-split-a-wav-file-into-multiple-wav-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitAudio(path):\n",
    "    t1 = 0\n",
    "    t2 = 1\n",
    "    tt1 = 0\n",
    "    tt2 = 0\n",
    "    audioList = []\n",
    "    while t2 <= 10:\n",
    "        print(t1)\n",
    "        tt1 = t1 * 1000  # Works in milliseconds\n",
    "        tt2 = t2 * 1000\n",
    "\n",
    "        newAudio = AudioSegment.from_wav(path)\n",
    "        newAudio = newAudio[tt1:tt2]\n",
    "        audioList.append(newAudio)\n",
    "        newAudio.export(str(t1) + '.wav', format=\"wav\")  # Exports to a wav file in the current path.\n",
    "        t1 = t1 + 1\n",
    "        t2 = t2 + 1\n",
    "\n",
    "    return audioList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função utilizada para o processamento do sinal do audio capturado e o transformando em um dataframe para ser utilizado posteriormente na predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateAudioFeatures(path):\n",
    "    fileName = path\n",
    "    print(path)\n",
    "    d = {'file': ['file'], 'genre': ['0'], 'mfcc': ['0'],'stft': ['0'],'chromagram': ['0'],'mel': ['0'],\n",
    "         'contrast': ['0'],'tonnetz': ['0'],'emotion': ['0']}\n",
    "    df = pd.DataFrame(d, columns=['file', 'genre', 'mfcc', 'stft', 'chromagram', 'mel', 'contrast', 'tonnetz', 'emotion'])\n",
    "\n",
    "    for Z in df.values:\n",
    "        sound, sr = librosa.load(fileName, res_type='kaiser_fast')\n",
    "        mfcc = np.mean(librosa.feature.mfcc(y=sound, sr=sr, n_mfcc=40).T, axis=0)\n",
    "        Z[2] = np.mean(mfcc)\n",
    "        # Fourier transformation\n",
    "        stft = np.abs(librosa.stft(sound))\n",
    "        Z[3] = np.mean(stft)\n",
    "        # Chromagram\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sr).T, axis=0)\n",
    "        Z[4] = np.mean(chroma)\n",
    "        # mel-scaled spectrogram\n",
    "        mel = np.mean(librosa.feature.melspectrogram(sound, sr=sr).T, axis=0)\n",
    "        Z[5] = np.mean(mel)\n",
    "        # spectral contrast\n",
    "        contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sr).T, axis=0)\n",
    "        Z[6] = np.mean(contrast)\n",
    "        # tonnetz\n",
    "        tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(sound),\n",
    "                                                  sr=sr).T, axis=0)\n",
    "        Z[7] = np.mean(tonnetz)\n",
    "    df = df.drop(['file'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função responsável pela classificação do genero do usuário. Utilizando o classificador com a seguinte parametrização: \n",
    "\n",
    "- random_state=2020\n",
    "\n",
    "- criterion='gini'\n",
    "\n",
    "- max_depth=6\n",
    "\n",
    "Os atributos utilizados foram: stft, chromagram, mel, contrast.\n",
    "\n",
    "A validação do modelo se deu pelo método de validação cruzado (cross-validation), e 5 distribuições de dados diferentes. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genreClassify(df_voices, df_target, path):\n",
    "    classifier_dt = tree(random_state=2020, criterion='gini', max_depth=6)\n",
    "    classifier_dt.fit(df_voices[['stft', 'chromagram',\n",
    "                      'mel', 'contrast']], df_target['genre'])\n",
    "\n",
    "    scores_dt = cross_val_score(classifier_dt, df_voices[['stft', 'chromagram', 'mel', 'contrast']],\n",
    "                                df_target['genre'], scoring='accuracy', cv=5)\n",
    "    print(\"Acurácia de Gênero: \" + str(scores_dt.mean()))\n",
    "    #SKTree.plot_tree(classifier_dt, fontsize=10)\n",
    "    #plt.show()\n",
    "\n",
    "    df_answer = generateAudioFeatures(path + '.wav')\n",
    "\n",
    "    x = float(classifier_dt.predict(df_answer[['stft', 'chromagram', 'mel', 'contrast']]))\n",
    "\n",
    "    #for x in df_voices['stft', 'chromagram', 'mel', 'contrast']\n",
    "\n",
    "    print(\"Resultado: \" + str(x))\n",
    "    if x == 0:\n",
    "        print(\"Áudio de uma mulher\")\n",
    "        return 0, df_answer\n",
    "\n",
    "    elif x == 1:\n",
    "        print(\"Áudio de um homem\")\n",
    "        return 1, df_answer\n",
    "\n",
    "    return -1, df_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "manEmotionClassify e womanEmotionClassify são os classificadores de emoções, para isso foram empregados os seguintes parametros: \n",
    "\n",
    "Para homem: \n",
    "\n",
    "- random_state=2020\n",
    "- criterion='entropy'\n",
    "- max_depth=7\n",
    "\n",
    "Para mulher: \n",
    "\n",
    "- random_state=2020\n",
    "- criterion='entropy'\n",
    "- max_depth=8\n",
    "\n",
    "\n",
    "O retorno tem o resultado da emoção capturada, de acordo com a lista de emoções previamente informada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manEmotionClassify(df_man_voices, df_man_target, df_predict):\n",
    "    classifier_manEmotion = tree(random_state=2020, criterion='entropy', max_depth=7)\n",
    "    classifier_manEmotion.fit(df_man_voices[['mfcc', 'stft', 'chromagram',\n",
    "                              'mel', 'contrast', 'tonnetz']], df_man_target['emotion'])\n",
    "\n",
    "    scores_dt = cross_val_score(classifier_manEmotion, df_man_voices[['mfcc', 'stft',\n",
    "                                'chromagram', 'mel', 'contrast', 'tonnetz']],\n",
    "                                df_man_target['emotion'], scoring='accuracy', cv=5)\n",
    "\n",
    "    print(\"Acurácia de Emoção H: \" + str(scores_dt.mean()))\n",
    "    answer = classifier_manEmotion.predict(df_predict[['mfcc', 'stft', 'chromagram',\n",
    "                              'mel', 'contrast', 'tonnetz']])\n",
    "    print(answer)\n",
    "    if answer[0] == 0:\n",
    "        return answer[0]\n",
    "\n",
    "    elif answer[0] == 1:\n",
    "        return answer[0]\n",
    "\n",
    "    elif answer[0] == 2:\n",
    "        return answer[0]\n",
    "\n",
    "    elif answer[0] == 3:\n",
    "        return answer[0]\n",
    "\n",
    "    elif answer[0] == 4:\n",
    "        return answer[0]\n",
    "\n",
    "    elif answer[0] == 5:\n",
    "        return answer[0]\n",
    "\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def womanEmotionClassify(df_woman_voices, df_woman_target, df_predict):\n",
    "    classifier_womanEmotion = tree(random_state=2020, criterion='entropy', max_depth=8)\n",
    "    classifier_womanEmotion.fit(df_woman_voices[['mfcc', 'stft', 'chromagram',\n",
    "                                'mel', 'contrast', 'tonnetz']], df_woman_target['emotion'])\n",
    "\n",
    "    scores_dt = cross_val_score(classifier_womanEmotion, df_woman_voices[['mfcc', 'stft',\n",
    "                                'chromagram', 'mel', 'contrast', 'tonnetz']],\n",
    "                                df_woman_target['emotion'], scoring='accuracy', cv=5)\n",
    "\n",
    "    print(\"Acurácia de Emoção M: \" + str(scores_dt.mean()))\n",
    "\n",
    "    answer = classifier_womanEmotion.predict(df_predict[['mfcc', 'stft', 'chromagram',\n",
    "                              'mel', 'contrast', 'tonnetz']])\n",
    "    print(answer)\n",
    "    if answer[0] == 0:\n",
    "        return answer[0]\n",
    "\n",
    "    elif answer[0] == 1:\n",
    "        return answer[0]\n",
    "\n",
    "    elif answer[0] == 2:\n",
    "        return answer[0]\n",
    "\n",
    "    elif answer[0] == 3:\n",
    "        return answer[0]\n",
    "\n",
    "    elif answer[0] == 4:\n",
    "        return answer[0]\n",
    "\n",
    "    elif answer[0] == 5:\n",
    "        return answer[0]\n",
    "\n",
    "    return -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função para limpar o armazenamento na lista de arrays das emoções "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resetValues():\n",
    "    global emotionStorage\n",
    "\n",
    "    emotionStorage = [[0, 0, 0, 0, 0, 0], \n",
    "                      [0, 0, 0, 0, 0, 0], \n",
    "                      [0, 0, 0, 0, 0, 0], \n",
    "                      [0, 0, 0, 0, 0, 0]]\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função que gera o relatório utilizando a lista de brinquedos que estão disponíveis para serem analisados e os dados resultantes da analise feita pela IA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildReport(emotionsRecorded):\n",
    "\n",
    "    rides = ['Roller Coaster', 'House of Monsters', 'Bumper Cars', 'Ferris Wheel']\n",
    "\n",
    "    emotions = ['Happy', 'Fear', 'Disgust', 'Sad', 'Neutral', 'Angry']\n",
    "    percentages = []\n",
    "\n",
    "    c = canvas.Canvas(\"report.pdf\")\n",
    "\n",
    "    c.setFillColor('grey')\n",
    "    c.setFont('Helvetica-Bold', 18)\n",
    "    c.drawString(400, 800, 'Rides Report')\n",
    "\n",
    "    count = 0\n",
    "    countRides = 0\n",
    "\n",
    "    for ride in rides:\n",
    "        c.setFillColor('grey')\n",
    "        c.setFont('Helvetica', 16)\n",
    "        c.drawString(50,750 - (count * 30), ride)\n",
    "        count += 1\n",
    "\n",
    "        for xTimesRecognized in emotionsRecorded[countRides]:\n",
    "            percentages.append(str((xTimesRecognized/10) * 100) + '%')\n",
    "\n",
    "        countRides += 1\n",
    "\n",
    "        for x in range(6):\n",
    "            c.setFillColor('grey')\n",
    "            c.setFont('Helvetica', 12)\n",
    "            c.drawString(100,750 - (count * 30), emotions[x])\n",
    "\n",
    "            c.setFillColor('red')\n",
    "            c.setFont('Helvetica', 12)\n",
    "            c.drawString(200,750 - (count * 30), percentages[x])\n",
    "            count += 1\n",
    "\n",
    "        count += 1\n",
    "        percentages = []\n",
    "\n",
    "        if countRides == 3:\n",
    "            c.showPage()\n",
    "            count = 0\n",
    "\n",
    "    c.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main - Carregando os arquivos e criando os datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recebendo dataset\n"
     ]
    }
   ],
   "source": [
    "aux = 0\n",
    "allFiles = os.listdir('./')\n",
    "for x in allFiles:\n",
    "    if x == 'Target.csv':\n",
    "        aux = aux + 1\n",
    "    elif x == 'Voices.csv':\n",
    "        aux = aux + 1\n",
    "    elif x == 'Voices_Male.csv':\n",
    "        aux = aux + 1\n",
    "    elif x == 'Target_Male.csv':\n",
    "        aux = aux + 1\n",
    "    elif x == 'Voices_Female.csv':\n",
    "        aux = aux + 1\n",
    "    elif x == 'Target_Female.csv':\n",
    "        aux = aux + 1\n",
    "\n",
    "if aux < 6:\n",
    "    print(\"Criando dataset\")\n",
    "    df, df_male, df_female = organizeDataFrames()\n",
    "    df_voices, df_target = generateFeatures(df, r'Target.csv', r'Voices.csv')\n",
    "    df_male_voices, df_male_target = generateFeatures(df_male, r'Target_Male.csv', r'Voices_Male.csv')\n",
    "    df_female_voices, df_female_target = generateFeatures(df_female, r'Target_Female.csv', r'Voices_Female.csv')\n",
    "    df_voices.head(600)\n",
    "elif aux == 6:\n",
    "    print(\"Recebendo dataset\")\n",
    "    df_voices = pd.read_csv('Voices.csv', sep=',', index_col=None)\n",
    "    df_target = pd.read_csv('Target.csv', sep=',', index_col=None)\n",
    "    df_male_voices = pd.read_csv('Voices_Male.csv', sep=',', index_col=None)\n",
    "    df_male_target = pd.read_csv('Target_Male.csv', sep=',', index_col=None)\n",
    "    df_female_voices = pd.read_csv('Voices_Female.csv', sep=',', index_col=None)\n",
    "    df_female_target = pd.read_csv('Target_Female.csv', sep=',', index_col=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main - Mostrando o menu principal com as opções de escolha dos brinquedos ou opções de sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###audio capture\n",
    "option = -1\n",
    "while 1:\n",
    "    print(\"0- Roller Coaster\\n1- House of Monsters\\n2- Bumper Cars\\n3- Ferris Wheel\\\n",
    "    n4- Display Data\\n5- Generate a Report\\n6- Reset Data\\n7- Exit\")\n",
    "    \n",
    "    option = int(input(\"Option: \"))\n",
    "    \n",
    "    while option < 0 and option > 7:\n",
    "        option = int(input(\"Invalid Option, insert your option again: \"))\n",
    "    audio = Loop(filename=\"audioTest\", threshold=False, max_seconds=10)\n",
    "    if option != 4 and option != 5 and option != 6 and option != 7:\n",
    "        print(\"Ouvindo\")\n",
    "        audio.listen()\n",
    "        audioList = splitAudio('./output/audio/audioTest.wav')\n",
    "        x = 0\n",
    "        for i in audioList:\n",
    "            answer, df_answer = genreClassify(df_voices, df_target, str(x))\n",
    "            x = x + 1\n",
    "\n",
    "            if answer == 0:\n",
    "                emotionAnswer = womanEmotionClassify(df_female_voices, df_female_target, df_answer)\n",
    "\n",
    "            elif answer == 1:\n",
    "                emotionAnswer = manEmotionClassify(df_male_voices, df_male_target, df_answer)\n",
    "\n",
    "            elif answer == -1:\n",
    "                print(\"Erro na identificação do sexo.\")\n",
    "\n",
    "            # 0: happy\n",
    "            # 1: fear\n",
    "            # 2: disgust\n",
    "            # 3: sad\n",
    "            # 4: neutral\n",
    "            # 5: angry\n",
    "            if emotionAnswer == 0:\n",
    "                emotionStorage[option][emotionAnswer] = emotionStorage[option][emotionAnswer] + 1\n",
    "\n",
    "            elif emotionAnswer == 1:\n",
    "                emotionStorage[option][emotionAnswer] = emotionStorage[option][emotionAnswer] + 1\n",
    "\n",
    "            elif emotionAnswer == 2:\n",
    "                emotionStorage[option][emotionAnswer] = emotionStorage[option][emotionAnswer] + 1\n",
    "\n",
    "            elif emotionAnswer == 3:\n",
    "                emotionStorage[option][emotionAnswer] = emotionStorage[option][emotionAnswer] + 1\n",
    "\n",
    "            elif emotionAnswer == 4:\n",
    "                emotionStorage[option][emotionAnswer] = emotionStorage[option][emotionAnswer] + 1\n",
    "\n",
    "            elif emotionAnswer == 5:\n",
    "                emotionStorage[option][emotionAnswer] = emotionStorage[option][emotionAnswer] + 1\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    elif option == 4:\n",
    "        print(emotionStorage)\n",
    "\n",
    "    elif option == 5:\n",
    "        buildReport(emotionStorage)\n",
    "\n",
    "    elif option == 6:\n",
    "        resetValues()\n",
    "\n",
    "    elif option == 7:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
